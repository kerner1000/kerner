\subsection{intrinsisch}
Bei der intrinsischen Genvorhersage werden proteinkodierende Gene, bzw.
\first{Open Reading Frames}, kurz \first{ORFs}, nur über bestimmte Merkmale in
der Sequenz selbst identifiziert.
\index{intrinsisch}
\index{Genvorhersage}
\index{Genvorhersage!intrinsisch}
\index{Open Reading Frame}
\index{ORF|see{Open Reading Frame}}
Solche Merkmale sind zum Beispiel Start- und Stopp-Codons (bei
Eukaryoten \geneseq{ATG} bzw. \geneseq{TAG}) oder Splice-Sites.
\index{Start Codon}
\index{Stop Codon}
\index{Splice Site}
Die Splice-Sites sind die Übergänge von Exon zu Intron und umgekehrt, und wenig
konserviert, was die Erkennung erschwert.
\index{Intron}
\index{Exon}
Üblicherweise sind die beiden Basenpaare unmittelbar vor einer
Splice Site \geneseq{AG} und unmittelbar hinter einer Splice Site \geneseq{GT}.

Die Erkennung dieser Sequenzcharakteristika ist keinenfalls trivial, da entsprechende
Merkmale nicht eindeutig, speziesspezifisch oder, wie bereits erwähnt, nicht
hinreichend konserviert sind.
Hier ist es nötig, sich verschiedenster Algorithmen und stochastischer
Modelle zu bedienen.

Üblicherweise bedienen sich moderne de novo \todo{was das?} Programme dem Hidden
Markov Model, das hier näher beschrieben werden soll.
\index{Hidden Markov Model}

\subsubsection{Hidden Markov Model}
Das \first{Hidden Markov Model} (kurz \first{HMM})
beschreibt ein System von (bekannten) Zuständen, die mit einer bestimmten
Wahrscheinlichkeit ineinander übergehen.
\index{Hidden Markov Model}
\index{HMM|see{Hidden Markov Model}}
\index{Zuständen}
Aus jedem der (verborgenen) Zustände entsteht mit einer
bestimmten Wahrscheinlichkeit ein zugehöriges Ausgabesymbol.
\index{Ausgabesymbol}

Als Beispiel für eine Problemstellung, die sich durch ein HMM dargestellten
lässt, betrachten wir folgendes Szenario:
Gegeben ist ein Stück Papier, auf dem die Buchstaben \enquote{hst}
gedruckt sind.
Diese Buchstaben sind Teil einer englischsprachigen Nachricht.
Offensichtlich handelt es sich bei dieser Buchstabenfolge um einen Tippfehler.
Es stellt sich also die Frage, welches Wort ursprünglich gemeint war.
Die erste Überlegung ist hierzu, dass im englischen dem Buchstabe \enquote{h}
nur sehr selten der Buchstabe \enquote{s} folgt.
Das ursprüngliche Wort könnte daher zum Beispiel \enquote{hot} oder auch
\enquote{hat} gewesen sein.
Es ist unwahrscheinlich, dass der Absender ursprünglich \enquote{hot} gemeint
war, da die Buchstaben \enquote{o} und \enquote{s} auf der Tastatur weit
auseinander liegen.
Wahrscheinlicher ist es, dass ursprünglich \enquote{hat} gemeint war, da das
Vertauschen von \enquote{s} und \enquote{a} ein häufiger Tippfehler ist, weil
\enquote{a} und \enquote{s} auf der Tastatur direkt nebeneinander liegen.
Weiterhin ist die Buchstabenfolge \enquote{ha} recht häufig in korrekt
geschriebenen, englischsprachigen Worten.

Übertragen auf die HMM Terminologie, sind die ursprünglich beabsichtigten
Buchstaben die verborgenen Zustände oder kurz \first{Zustände}, die tatsächlich
auf dem Papier gedruckten Buchstaben die \first{Ausgabesymbole}, oder
\first{Beobachtungen}.
\index{Zustände}
\index{verborgener Zustände|see{Zustände}}
\index{Ausgabesymbol}
\index{Beobachtung}
 Die Übergangswahrscheinlichkeiten sowie die Beobachtungswahrscheinlichkeiten
 werden durch die Überlegungen zur richtigen Schreibweise in der englischen
 Sprache und der Tastenanordnung auf einer Tastatur, bzw. die tatsächlich auf
 dem Papier gedruckten Buchstaben repräsentiert.
 \index{Wahrscheinlichkeiten!Übergangs}
\index{Wahrscheinlichkeiten!Beobachtungs}

Auf die selbe Weise kann das HMM auf de novo \todo{was das?} Genvorhersagen
angewendet werden:
\index{de novo}
\index{HMM}
Die Beobachtungen sind die Basen der Zielsequenz, die verborgenen Zustände die
biochemische Funktion, die diese ausüben.

Üblicherweise kommt bei der Genvorhersage eine spezielle Form der HMM zum
Einsatz, das \first{Generalized Hidden Markow Model}, kurz \first{GHMM}:
\index{GHMM|see{Generalized Hidden Markow Model}}
\index{Generalized Hidden Markow Model}
Der Unterschied zu gewöhnlichen HMMs besteht darin, dass bei einem GHMM die
Beobachtungen nicht durch nur eine Base, sondern durch eine Basenfolge
beliebiger Länge dargestellt sind.
Die Zustände können so Sequenzabschnitten zugeordnet werden, wie z.B. Intron,
Exon oder Splice Site.
\index{Intron}
\index{Exon}
\index{Splice Site}
\index{Zustände}
Die Übergangswahrscheinlichkeiten werden durch Wichtungs-Matrizen
repräsentiert, die allen Positionen innerhalb des Sequenzabschnittes die vier
Basen mit einer bestimmten Auftrittswahrscheinlichkeit zuordnen.
\index{Wahrscheinlichkeit!Übergangs}
\index{Wichtungs-Matrix}
\index{Wahrscheinlichkeit!Auftritts}
Diese Matrizen beinhalten in der Regel sepeziesspezifische Werte, sodass ein
\name{Training} des Algorithmus, also das Anpassen dieser Matrix auf die für die
Spezies typischen Werte erfolgen muss.
\index{Alogrithmus}
\index{Training}
\index{Matrix|see{Wichtungs-Matrix}}
Die Genauigkeit von GHMM hängt maßgeblich von den verwendeten
Wichtungs-Matrizen ab.
\citep{pmid16339376, pmid17687368, pmid10779491, durbin_biological_1998}

\subsubsection{maximum entropy Markov model}
\index{MEMM|see{maximum entropy Markov model}}
\index{maximum entropy Markov model}

\subsubsection{Conditional Random Fields}
\todo{ui ui ui}